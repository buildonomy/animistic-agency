#+AUTHOR: Andrew Lyjak
#+EMAIL: andrew.lyjak@gmail.com
#+OPTIONS: todo:nil
#+OPTIONS: toc:nil
#+OPTIONS: tags:nil
#+OPTIONS: prop:Effort
#+OPTIONS: ^:{}
#+STARTUP: indent
#+COLUMNS: %TODO %PRIORITY(P) %70ITEM(Task) %TAGS %8Effort(Estimated Effort){:} %DEADLINE
#+TAGS: h3d alyjak sow_1 sow_2 upkeep
#+PROPERTY: Effort_ALL 0 1:00 2:00 4:00 8:00 16:00 24:00 40:00 80:00

* TODO H3D SOW #1                                                 :h3d:sow_1:
The tasks and services agreed upon by the parties listed within the Consulting Agreement are
described herein. Work is divided into payment milestones, who's description and price is described
within the [[milestones][following table]]. Payment is expected upon completion of each milestone. The total
contract value, consisting of the sum of each milestone, is listed as the first line item of the
table. After notification by the consultant, *A Lyjak Cybernetics Consulting LLC*, the Client's
technical authority for the contract, *Jason Jaworski*, is responsible for affirming that all
sub-tasks enumerated within a milestone are confirmed satisfactorily complete. Evaluation is
expected within *10* business days of receiving notice of milestone completion. Payment is expected
within *one month* of an affirmative evaluation. It is the consultant's responsibility to respond
and incorporate feedback based on the technical authority's review before re-notifying the client of
milestone completion.


*Hourly Rate: $120/hr*

#+NAME: milestones
#+BEGIN: columnview :format "%ITEM(Task) %Effort(Effort){:} %Price(Price)" :hlines 2 :maxlevel 2
#+CAPTION: Estimated effort (HH:MM) and price for the SOW (row 1) and each sub-milestone therof
| Task                                       | Effort |    Price |
|--------------------------------------------+--------+----------|
| H3D SOW #1                                 | 207:00 | 24840.00 |
|--------------------------------------------+--------+----------|
| Detector QC Configuration and Verification |  27:00 |  3240.00 |
|--------------------------------------------+--------+----------|
| Extract Open Source Software from H3ID     |  88:00 | 10560.00 |
|--------------------------------------------+--------+----------|
| Capture Calibration Data and Store in H3ID |  68:00 |  8160.00 |
|--------------------------------------------+--------+----------|
| Golden Archive Rendered Template Override  |  16:00 |  1920.00 |
|--------------------------------------------+--------+----------|
| Update production server                   |   8:00 |   960.00 |
#+TBLFM: $3=$2*120;tE
#+END:
#+TBLFM: $3=$2*120;tE


** DONE Detector QC Configuration and Verification

This task is focused on ensuring H3D is using the full capabilities of the detector burner and
updater. The main focus is ensuring configuration file templates are produced correctly and the
operator is aware and in-control of what is going on during an image burn/update.

Completing this milestone entails designing, implementing, testing, and/or reviewing the following
tasks:

*** DONE Ensure all systems with model codes assigned are valid
   :PROPERTIES:
   :EFFORT:   24:00
   :END:

Because of how the first iteration of model codes worked, some units may have inadvertently received
a default model code which does not match their actual specification. Clean this up by auditing all
detector's codes against data on monday.com. Create a list of correct codes for all detectors, where
the "correct" value may be unset if we have not defined a code yet for that detector family.

Instead of auditing this way, add an interface which prevents default codes from being ingested
during burn image/update.

*** DONE Set RTC
   :PROPERTIES:
   :EFFORT:   2:00
   :END:

Sync RTC with time from h3id by logging onto the system and setting the clock.

Log onto the system, run two shell commands to sync the time with h3id. Run:

#+BEGIN_SRC bash
date +%Y%m%d -s "20230103"
date +%T -s "15:45:00"

# And the following command to sync the RTC to the current system time:
hwclock -w
#+END_SRC

*** DONE Verify customer ID is set correctly
    :PROPERTIES:
    :EFFORT:   1:00
    :END:

Customer id is already written to the templates (when customer id is defined), but we need to verify
it's set correctly for IAEA detectors.

** TODO [#C] Extract Open Source Software from H3ID

This milestone is complete when the base software and configuration-as-code infrastructure has been
extracted from H3ID into a separate project such that:

- The base software can be open sourced without any risk to H3D in terms of liability or risk of
  exposing proprietary secrets.
- H3ID still works, using the newly extracted project as its base dependency.

Completing this milestone entails designing, implementing, testing, and/or reviewing the following
tasks:

*** TODO Rename group to model
     :PROPERTIES:
     :EFFORT:   4:00
     :END:

Group is awkward pedagogically. I think the term 'model' better represents the function of that
database object. Task involves search/replace variable names and documentation, and verifying the
migration works correctly.

*** TODO Rename unit to instance
     :PROPERTIES:
     :EFFORT:   4:00
     :END:

Unit is awkward pedagogically. I think the term 'instance' better represents the function of that
database object. Task involves search/replace variable names and documentation, and verifying the
migration works correctly.

*** TODO Extract H3D-specific Capability modules
    :PROPERTIES:
    :EFFORT:   16:00
    :END:

Known H3D specific modules are, production, embedded, detector, customer, and console (all defined
capabilities minus the root one). For marketing purposes I would like to fork/extract example
capabilities based on production, embedded, and console.

*** TODO End-to-End code review to Extract H3D-specific Variable names, defaults, and documentation.
    :PROPERTIES:
    :EFFORT:   16:00
    :END:

Review variable names, defaults, functions, and comments in each file to ensure H3D-specific data is
removed from the open source core.

*** TODO Respond to final Code Review
    :PROPERTIES:
    :EFFORT:   4:00
    :END:

Create a code review that is focused on demonstrating that proprietary and open source material have
been successfully separated. Respond to all comments.

*** TODO Rebrand de-proprietarized H3ID to buildonomy
    :PROPERTIES:
    :EFFORT:   8:00
    :END:

Tentative name: buildonomy

- *build*: the act of constructing
- *-onomy*: describing laws or methods

Highlights the application as a place to structure the laws and methods used for building something
together. The application becomes a place where product lifecycle management tasks are constructed,
coordinated, and evolved.

Relates to the ideas of taxonomy and economy. We are trying to classify all the subsystems of our
build process as well as structure the push and pull of diverse values along the entire product
lifecycle.

*** TODO Demonstrate build/deploy of H3ID using buildonomy dependency
    :PROPERTIES:
    :EFFORT:   8:00
    :END:

For this update, the most difficult piece is likely to be hand-editing migrations.

*** TODO Publish to Gitlab/pypi with Apache 2.0 License
    :PROPERTIES:
    :EFFORT:   4:00
    :END:

The Apache 2 license is permissive for other persons/companies forking the code and selling it as
their own product without open source licenses. This is a pro and a con, as it lowers the friction
of companies/businesses who are considering adopting it but don't want to be restricted in their
final usage. It could also really hurt me though, if some big cahuna grabs it and markets it as
their own thing. I think I'm ok with that risk.

The other special-ish thing about the license is that it has a patent suit dead-mans switch. It says
that users are granted patent rights to any patent claims made by any of the software's developers,
but those rights are revoked to any organization that sues the software developers.

https://en.wikipedia.org/wiki/Apache_License
https://www.apache.org/licenses/LICENSE-2.0.html
https://packaging.python.org/en/latest/tutorials/packaging-projects/

*** TODO Train H3D on how to independently update and provision the service
    :PROPERTIES:
    :EFFORT:   24:00
    :END:

This is a combination of documentation and on-site training to:

- Spin up a new instance from a fresh VM.
- Restart the service after a reboot.
- Update LDAP group permissions.
- Perform a database migration.
- Use the ~h3id_client~ command line utility to update the database according to a predefined
  default dictionary.
** TODO [#A] Capture Calibration Data and Store in H3ID
Define and implement a schema and associated API functionality that delineates calibration data from
other system configuration information. This functionality will enable product lifecycle-aware
application and extraction of calibration data to and from system configuration files.

*** TODO Create a dictionary schema in the production spec that determines merge arguments for calibration data
:PROPERTIES:
:EFFORT:   24:00
:END:
Certain keys should prioritize user settings (eg timezone), whereas other's should prioritize
database values (because Brian's scripts push there directly). Having this type of schema should
resolve that. There may even be optional/required keys, this can be used to hold of detector update
operations until calibration data is loaded.

- [ ] Define the schema; mapping filenames to nested variables, to the schema arguments
- [ ] Update client/defaults.json with the new calibration schema.
- [ ] Create unit tests for each file type enabled in the schema
- [ ] Allow keys specified in the schema to define valid value types and ranges.
*** TODO Create Production JSON field to store an unstructured dictionary of key:value pairs
:PROPERTIES:
:EFFORT:   4:00
:END:
*** TODO Create an API endpoint to get,set,delete keys in the calibration data json field
:PROPERTIES:
:EFFORT:   4:00
:END:
Include unit tests
*** TODO Create an API endpoint to start a detector update
:PROPERTIES:
:EFFORT:   8:00
:END:
Have it return the burn log id. Poll the burn log id to see the burn state. Include unit tests
*** TODO Wrap the dictionary in a codemirror block for viewing and editing, similar to option schema
:PROPERTIES:
:EFFORT:   8:00
:END:
*** TODO Add a parse step in create_archive to get key:value pairs from SystemSettings.xml and Polaris_H3DBNL.ini
:PROPERTIES:
:EFFORT:   16:00
:END:
Parses a new archive and tries to push to the calibration field. Have a user-input prompt come up if:

- [ ] there's irreconcilable differences between the two, or
- [ ] the reconciled value does not match the valid range/type specified for that value.
*** TODO Add a validator step when staging configs
:PROPERTIES:
:EFFORT:   4:00
:END:

such that has a user-input prompt come up if there are variables within the staged file that do not
pass the variable-specific type and range arguments.
** TODO [#B] Golden Archive Rendered Template Override
:PROPERTIES:
:EFFORT:   16:00
:END:
Add a field to burn logs that allows them to be flagged as a golden archive. If a golden archive is
flagged for a particular detector, then do not render templates, instead populate the staging
filesystem with the files within/linked to the archive. Then when synchronizing filesystems, this
will enable the user to view differences between the detector's filesystem and the archive, rather
than between the detector and the rendered templates. Only allow one golden archive per detector.

Question: Doesn't archive already do something like this? When you commit changes using the UI,
doesn't it archive what the user specified?
** TODO Update production server
:PROPERTIES:
:EFFORT:   8:00
:END:
Run the update server procedure, ensuring to push new defaults (calibration key schema files), and
create and save new migrations.

* TODO H3D SOW #2                                                 :h3d:sow_2:
#+BEGIN: columnview :format "%ITEM(Task) %Effort(Effort in HH:MM){:} %Price(Price in $)" :hlines 2 :maxlevel 2
#+TBLFM: $3=$2*120;tE
#+END:

This Statement of Work will take place after buildonomy is updated with up-to-date dependencies and
the new Aggregator backend feature.

** TODO Update Patches [Total Milestone]
  :PROPERTIES:
  :END:

H3D Update patches are incrementally applied to detector's system image in order to resolve bugs,
add features and otherwise customize the application stack after the base detector image has been
applied to the hardware.

Modify the detection, application, and display of update patches onto detectors by designing,
implementing, testing, and/or reviewing the following tasks:

*** TODO Operator controls what patch to apply
    :PROPERTIES:
    :EFFORT:   24:00
    :END:

When the detected and expected patch differ, Have the operator specify whether to preserve the
out-of-date patch or apply the latest patch.

The operator should be provided with a list of all valid patches available for the unit with the
latest, most-specific highlighted as the recommended option.

If there are customer-specific patches available, they should be listed and preferentially sorted in
the available patch list.

*** TODO Operator must confirm the option codes are correct
     :PROPERTIES:
     :EFFORT:   24:00
     :END:

Prior to burning or updating a detector, If the model code, and/or config code are not set, operator
must confirm that it should use the default code. The default code will be displayed to the operator
for this operation.

*** TODO Detect and store what patch is currently applied to the unit
    :PROPERTIES:
    :EFFORT:   16:00
    :END:

For detector status, detect at most once a day. This involves creating multiple different status
polls with different frequencies of operation.

Design it such that the long status (this operation + "is dirty" checks) only occur on detectors
that are marked available by the latest high frequency check.

Burning or updating a detector already records what patch was applied and verifies the patch file
was not corrupted during transfer to the end file location.

*** TODO Detect and store if the detector's patch is out of date
    :PROPERTIES:
    :EFFORT:   8:00
    :END:

Display a warning if there is a latest patch available that is applicable to the unit's model family
that is not currently loaded onto the detector.

*** TODO Provide an upload frontend for patches
:PROPERTIES:
:EFFORT:   8:00
:END:

Using this H3ID frontend, a user uploads a patch, H3ID parses the metadata within the patch,
generates a standard name for the patch from that metadata, and uploads it to the patch repository
on artifact.

As part of this effort, re-upload all patches to ensure they are named correctly.

*** TODO Update the patch application algorithm to prioritize customer group specific patches
:PROPERTIES:
:EFFORT:   8:00
:END:

Patch application decides what the 'latest' patch for any particular detector based on what patch
most closely matches the detector's serial number. Update this such that patches can be categorized
to only apply to particular customer groups, and such that customer groups factor into deciding what
the most-specific, latest patch is for a detector.

*** TODO Verify patch was applied correctly
    :PROPERTIES:
    :EFFORT:   24:00
    :END:

Verify that a detector's expected software application executables hash matches the actual
executables hash calculated from reading the filesystem.

Perform this check for low frequency detector status polls (See "Detect and store what patch is
applied" above), and detector update operations. Fail a burn if the check during a detector update
fails. Note we can't perform this operation for detector image burns as the patch is only applied on
systems after they are booted.

Note that we currently calculate an md5sum for the 'application' file partition, but this is
different than comparing to the patch. See ~PARTITION_GROUPS_~ in ~h3id/app/embedded/__init__.py~
and ~PARTITION_GROUP['application']~ in ~h3id/app/embedded/constants.py~ for the meaning of the
'application' file partition. This does not account for the expected version information stored in
the patch. The 'application' file partition is used for determining if a system's current
application-related files have been archived or not.

*** TODO Tableview: Show what patch is applied
    :PROPERTIES:
    :EFFORT:   4:00
    :END:

On the detector burn logs, status, and main tables, show the patch name (if any) applied to the
detector. For the main detector table, Grab the patch name from burn logs, update logs, or detector
status logs, whichever log is newer.

*** TODO Tableview: Show detector patch "is latest" status
    :PROPERTIES:
    :EFFORT:   4:00
    :END:

On the detector status and main tables, show if the applied patch is the latest patch for that
model.

*** TODO Tableview: Show detector patch "is dirty" status
    :PROPERTIES:
    :EFFORT:   4:00
    :END:

On the detector status and main tables, show if the applied patch and installed executable versions
match.
** TODO IAEA Efficiency Parameter Utilities
*** TODO Check efficiency parameters
    :PROPERTIES:
    :EFFORT:   24:00
    :END:

This could be implemented with the future buildonomy Aggregator feature.

Efficiency parameters are accessible via the :8080 page.

NEED REVIEW: When performing detector status queries, if the detector is part of the IAEA set,
compare the reported efficiency parameters against their expected ranges. On the detector status
tableview, add display/filter to select detectors who's efficiency is out of range.

This can be implemented using the detector status infrastructure updates necessary to implement the
patch verification task
*** TODO uC setting check
   :PROPERTIES:
   :EFFORT:   4:00
   :END:

Set the microcontroller setting in the detector's configuration file templates. Need to work with
the DAQ team to know how to extract this information out of what we have available.

NOTE: Punt to SOW #2, do with the IAEA work. Jason will look at whether we can change the procedure
here and just write a file.

*** TODO Verify temp float settings
   :PROPERTIES:
   :EFFORT:   2:00
   :END:

This mostly done, just need to verify settings are interpreted correctly.

Punt to SOW#2, involves reading 8080.

1. Make sure there is a particular number in several locations on the page. Should show that there's
   12 points for each crystal.
1. There's a table that's used for efficiency parameters. The only way to verify is to check a .png
   right now. Punt until the dev team creates a machine readable efficiency parameter validation
   table that's accessible via h3id.
** TODO Upgrade Installation
*** TODO Update and re-pin dependencies (python, docker, javascript) :sow_2:
     :PROPERTIES:
     :EFFORT:   4:00
     :END:

Task involves re-pinning all dependencies to their latest versions, then debugging the inevitable
downstream library API changes.

We'll put this in SOW 2, this way I can upgrade dependencies on builonomy, and then during SOW_2 we
can demonstrate that H3ID maintains the capability of pulling in upgrades from buildonomy.

* H3D General Invoicing
** DONE Write up Option Code Documentation
:PROPERTIES:
:EFFORT:   1:00
:DEADLINE: <2023-06-01 Thu>
:END:
** DONE Server Upgrade
:LOGBOOK:
CLOCK: [2023-06-07 Wed 14:04]--[2023-06-07 Wed 15:48] =>  1:44
CLOCK: [2023-06-07 Wed 10:36]--[2023-06-07 Wed 13:27] =>  2:51
CLOCK: [2023-06-07 Wed 07:43]--[2023-06-07 Wed 09:56] =>  2:13
CLOCK: [2023-06-06 Tue 12:37]--[2023-06-06 Tue 16:44] =>  4:07
CLOCK: [2023-06-05 Mon 10:54]--[2023-06-05 Mon 11:51] =>  0:57
CLOCK: [2023-06-05 Mon 07:34]--[2023-06-05 Mon 10:32] =>  2:58
CLOCK: [2023-06-05 Mon 05:53]--[2023-06-05 Mon 06:07] =>  0:14
CLOCK: [2023-06-05 Mon 05:30]--[2023-06-05 Mon 05:50] =>  0:20
CLOCK: [2023-06-04 Sun 05:27]--[2023-06-04 Sun 06:36] =>  1:09
CLOCK: [2023-06-03 Sat 05:32]--[2023-06-03 Sat 05:59] =>  0:27
CLOCK: [2023-06-02 Fri 14:31]--[2023-06-02 Fri 15:17] =>  0:46
CLOCK: [2023-06-02 Fri 07:35]--[2023-06-02 Fri 12:30] =>  4:55
:END:
- [X] Reset test to prod version and sync database
- [X] Debugged inability to access burner on prod. Root cause has something to do with redis. The
      client was unable to create a websocket connection. The server had a gunicorn_error related to not
      able to connect to redis. Restarted redis and was able to reconnect but the restart killed the
      workers. Restarted the workers and everything was back to normal.
- [X] Update test to model_schema branch and perform migration
- [X] Spot check everything is working
- [X] Fix tab anchor regression and related codemirror refresh issue
- [X] Remove `command` file from AsRun Logs
- [X] Fix config diff comparison. 'Detector' version isn't actually on the detector
- [X] Split update_unit into update_patch and update_config per discussion with Jason
- [X] Merge model_picker branch to master
- [X] Update prod to master and perform migration
- [X] Run h3id_client update to sync h3d model code schemas. Ran ~REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt h3id_client --host https://h3id.h3dgamma.com --user alyjak --pdb update --updates h3id/app/client/defaults.json -o build.model_code build.config_code spec.model_codes spec.model_schema spec.config_codes~
- [X] Send email to h3d
** DONE Tag up with Jason
:LOGBOOK:
CLOCK: [2023-06-06 Tue 11:01]--[2023-06-06 Tue 11:47] =>  0:46
CLOCK: [2023-06-08 Thu 16:01]--[2023-06-08 Thu 16:20] =>  0:19
:END:
** TODO Jason Call
:LOGBOOK:
CLOCK: [2023-07-11 Tue 07:14]--[2023-07-11 Tue 07:52] =>  0:38
CLOCK: [2023-07-06 Thu 14:38]--[2023-07-06 Thu 15:59] =>  1:21
CLOCK: [2023-07-06 Thu 13:18]--[2023-07-06 Thu 14:31] =>  1:13
CLOCK: [2023-06-13 Tue 14:12]--[2023-06-13 Tue 14:46] =>  0:34
:END:

2023-07-06: debugging why Jason wasn't seeing diffs after he modified templates for an H400. Looks
like the template mods he did were all whitespace in which case the diff wont appear as it
normalizes and auto formats between the versions in order to only show material changes.
** TODO 'Max' burn failing
:LOGBOOK:
CLOCK: [2023-06-14 Wed 08:41]--[2023-06-14 Wed 09:58] =>  1:17
:END:
Also fixed model code and option code not rendering on production build tab
also fixed `command` file not getting removed from asrun artifact zips
** TODO Chris SSU Boss unit creation incorrect ipv6 issue
:LOGBOOK:
CLOCK: [2023-06-26 Mon 09:00]--[2023-06-26 Mon 11:27] =>  2:27
CLOCK: [2023-06-26 Mon 08:27]--[2023-06-26 Mon 08:38] =>  0:11
:END:
also reviewed issue from Travis re M-00-01-220
and drafted a fix for a render bug for displaying unit model codes
** Burner not working
:LOGBOOK:
CLOCK: [2023-07-18 Tue 15:00]--[2023-07-18 Tue 15:24] =>  0:24
:END:

** TODO Add 'Unallocated' state to production status
:LOGBOOK:
CLOCK: [2023-08-29 Tue 12:15]--[2023-08-29 Tue 12:46] =>  0:31
CLOCK: [2023-08-17 Thu 12:03]--[2023-08-17 Thu 12:16] =>  0:13
CLOCK: [2023-08-16 Wed 13:44]--[2023-08-16 Wed 14:55] =>  1:11
CLOCK: [2023-08-16 Wed 11:28]--[2023-08-16 Wed 12:48] =>  1:20
:END:

* TODO Buildonomy                                                    :alyjak:
  :PROPERTIES:
  :EFFORT:   0:00
  :END:

Buildonomy realizes that each project has a life of its own. At its best, Product Lifecycle
Management software enables us to interact with our projects as designers, builders, caretakers,
scientists, constituents, and customers. As users of PLM software, its our job to define what that
life looks like in reality. To really give a project life, we must be able to dynamically coordinate
together from all the diverse perspectives that make a project successful. Buildonomy provides a
fundamental grammar empowers your team to self-create the interfaces, records, and automation that
provide the greatest value to who you are and what you are trying to accomplish. With Buildonomy,
you don't need separate platforms for your lean startup versus your industry giant, as the
capabilities of buildonomy stretch to fit the speed and agility of a small team or the standards and
precision of a mature and complex endeavor.

When you adopt Buildonomy, you don't need to worry about a costly and abrupt transition period. With
Buildonomy's advanced aggregation and synchronization capabilities, you can integrate
buildonomy-native data with your existing services in order to expose coherent task-driven
interfaces to your project.


*Core Building Blocks:*

*Capabilities:* Each capability organizes the data and activities necessary to perform a core PLM
function. Each new capability represents the product uniquely in terms of the model, instance, and
aggregate representations of the item. Together, the set of faculties mapped to a product define the
engineering, production, sales, and services tasks and data necessary to reliably and efficiently
build a line of products.

Capabilities provide a byline to natively connect Model, Instance, and Aggregate views of a product
lifecycle within the database. This facilitates natural growth of the power and interpretability of
the underlying processes as they grow and develop.

Every Model, Instance, and Aggregate view of a capability has access to the following
operator-managed tool-suite.

*Models:*

*Instances:*

*Aggregators:* The core idea is that digital twins need active management to stay a part of the real
development workflow during all stages of the product development lifecycle. Different paradigms and
coordination mechanisms are necessary for each sub-system of along each different lifecycle phase.

By integrating user-configurable automation and procedure support not as a secondary attribute that
just makes interfaces easier to navigate, but rather as the core constituent of each sub-system's
function (the function is the agent), interfaces can grow, adapt and become less cumbersome more
efficiently than if those facilities were dependent on coders and other infrastructure experts to
implement.

*AeSoP:* Each capability defines data, processes (automated and manual), and state in relation to a
shared model id. The web of procedures tied to the item, both completed and planned, describe its
current state.

Contains the logic for user-defined defined procedural state machine. Context-driven operator tasks,
transition criteria, workspaces, and automation are all collected into a single user-defined
interface.

*Assembly:* Define assemblies and other structured dependency relationships among capability IDs of
the same lifecycle type.

** Sales and Marketing
:PROPERTIES:
:EFFORT:   0:00
:END:
*** TODO Create Articles
**** [#A] Why buildonomy
**** [#A] What are Capabilities
**** What is AESOP
**** Design your Capabilities
    :PROPERTIES:
    :EFFORT:   0
    :END:
**** Working with Workers
    :PROPERTIES:
    :EFFORT:   0
    :END:
*** TODO [#A] Set up website
:PROPERTIES:
:EFFORT:   0
:END:
**** Set up SEO as well
*** Market Research
**** TODO SE Michigan Companies
:PROPERTIES:
:EFFORT:   0
:END:
**** DONE [#A] Go to automate conference May 22-25
DEADLINE: <2023-05-22 Mon>
**** TODO Research PLM/digital twin competitors
https://www.g2.com/categories/digital-twin
https://www.g2.com/categories/plm

Try and find out what the total addressible market is. Try and answer the questions from this
article: [[https://www.thediff.co/archive/100-due-diligence-questions-checklist/?ref=the-diff-newsletter][A Short 100-Question Diligence Checklist]].

Also Explore Project Management space:
https://coda.io/compare/
https://www.notion.so/compare-against/notion-vs-monday

Roam Zettlekasten space.
https://roamresearch.com/
https://subconscious.network/

**** TODO Create User Survey
*** Dogfood plan
Can I use buildonomy to run the business of consulting/developing buildonomy?
*** DONE [#A] Buildonomy Logo
*** TODO [#A] Business Cards
DEADLINE: <2023-05-22 Mon>
Need logo complete
** DONE Buy buildonomy.com
costs about $2k. Do this with initial subscription profits. Bought in order to have that email
address in order to (hopefully) interact with verses.ai sometime. Also bought google workspace for
email/document/drive management.
** Accounting and Law
*** TODO Become an amateur in accounting and tax law
[[https://www.irsvideos.gov/Business/SBTW][Small Business Tax Workshop]]
[[https://www.irs.gov/publications/p3402][Taxation of Limited Liability Companies]]
**** DONE Decide on Entity Classification Election (IRS form 8832)
[[https://www.irs.gov/publications/p3402][Publication 3402 (03/2020), Taxation of Limited Liability Companies]]


Decision: Stay a pass through entity. Can become a partnership without suffering the 60mo
re-election limit. Don't want to add the (time+money) expense of managing an S or C-corporation.

Open question: If trying to raise venture funding, will probably have to liquidate, transfer
ownership of buildonomy.

**Subsequent Elections**

An LLC can elect to change its classification. Generally, once an LLC has elected to change its
classification, it can't elect again to change its classification during the 60 months after the
effective date of the election. An election by a newly formed LLC that is effective on the date of
formation isn't considered a change for purposes of this limitation. For more information and
exceptions, see [[https://www.law.cornell.edu/cfr/text/26/301.7701-3][Regulations section 301.7701-3(c)]] and the [[https://www.irs.gov/forms-pubs/about-form-8832][Form 8832]] instructions.

An election to change classification can have significant tax consequences based on the following
transactions that are deemed to occur as a result of the election.
*** TODO Quarterly Tax Payments
DEADLINE: <2023-06-05 Mon +3m>

To Michigan and to IRS
** TODO Development
:PROPERTIES:
:EFFORT:   0:00
:END:
*** TODO SASS:
**** TODO [#A] GPDR-compliant user management
**** TODO Credit card subscription billing
**** TODO [#A] Cloud installation
What architecture?
What provider?
*** TODO Service monitoring
:PROPERTIES:
:EFFORT:   0
:END:
*** TODO [#A] Define Aggregators and incorporate into Capabilities
:PROPERTIES:
:EFFORT:   0
:END:
Aggregators work on an API query and a trigger condition in order to synchronize and post process
work.
*** TODO [#A] AsRun Artifact Abstraction
*** TODO Custom Tableviews

Requires standardized interface between

- ~model~ $\rightleftarrows$ ~Asrun~
- ~instance~ $\rightleftarrows$ ~Asrun~

Intent is to create a db object that defines a table and search criteria. The table is mapped to
users or groups, who have permission to view the table. Can hook in email when the table content
changes.
*** TODO Vault
Need a lattice-style authorization mechanism to control access to CRUD operation/automation
secrets. This way we can be reasonably sure we don't create a backdoor into connected services by
the credential management necessary to allow the aggregators to function appropriately.
**** TODO Search results should be filtered based on user lattice permissions
This applies to NestedFilter and Version History results in particular.
*** TODO Interface Interaction Focus Points
What we're handling here is complex evolving relationships across a spectrum of formalization. Need
to focus on interfaces for reliable interaction with this information such that operators are
empowered to maintain it. Notable views include:

- assembly view
- state machine
- task definition (ansible runner, etc)
- aggregator definition
- table definition
- Review and Approval Workflows
- Cross-PLM view (how model, instances, aggregators connect)
*** TODO Dynamic capability/aggregator definition
If authorized users can define the data model for aggregators and even capabilities within the
application itself, that would go a long way to the goal of buildonomy being a universal
workflow/procedure system.

https://stackoverflow.com/questions/7933596/django-dynamic-model-fields/7934577#7934577

*** TODO Subassemblies
**** DONE Edit children
**** DONE Graph View
n**** DONE Edge Type
   Type specific edge metadata
**** TODO Import SpecAssemblies
**** TODO Logic Nodes:Abstract Spec nodes/Decision Point Nodes:
   Create Capability/Capabilities to perform the following assembly logic

   1) Option Set Array/List definition
   2) Procedure/Quality Gate
   3) Requirement/Documentation/Code Set

   Make disabled Capabilities not display
**** TODO Track and share a changelog with each subassembly
*** Production Workflow
**** pull kit/assembly information from FishBowl
**** Create a Dashboard for showing workorders
   Sort, filter (default open only)
   capacity to view, assign, and close
**** Map workorders to H3ID-truth'd procedures
   sub procs for:
   - calibration
   - configuration
   - QC
**** Add order form for initiating workorders
   Be able to map to 'build new unit' vs 'configure inventoried unit'
***** Trigger new inventory order if inventory missing
**** Create POs in H3ID
***** Handle GPDR
***** Specify security constraints for operating outside of VPN
**** TODO identify the buildstate of units
Jason is pretty sure that Chris et al. when they want 'next sn/mac' they mean next to build, not
next to assign.
*** TODO [#A] Email
**** User Email preferences
**** Email generation trigger points:
   - CI
   - production workflow
   - unit/group changes
*** Misc
**** TODO [#C] Update the Domain Controller with the latest mapping of detector name to ipv6
**** TODO clone a unit queryset at the version it was at the burn timestamp
   In a further effort to make burns reproducible, be able to clone a unit query at a specific
   schema/state in time.
**** [#C] Datatables filters: integrate select2 selectors for related links
** Issues
*** Request Latency and database transactions
Need to get a handle on request performance.
- Need to get an end to end profile of request calls
- Need to dramatically cut down the number of db calls when inside the capabilitymanager
*** Unit Management when Deleting a Group
When removing groups, prompt when that will leave units unassigned. In general, when units are
affected at all by a group removal, the user needs to be included in the decision on how to proceed.
*** Re-Mapping Units
When updating a group version, prompt when units are assigned to the old, but not yet fully built as
to whether they should be re-mapped to the new group version.
** Features

Provided by GPT-4 and chat GPT
*** Project Management
A feature that allows users to manage their projects from start to finish, including setting goals,
tracking progress, and assigning tasks to team members.

buildonomy would make it easy to manage projects by providing a comprehensive overview of tasks,
timelines, deliverables, and milestones. Users can also assign tasks, and collaborate on projects
with team
**** Setting Goals
**** Tracking Progress
**** Assigning Tasks
*** Version Control
The application would also allow for version control of designs, bills of materials, and other
documents. This would enable users to keep track of changes in real-time and avoid conflicts or
errors in the design or production process.
**** Track Changes
**** Branch
**** Merge
**** Rollback
*** Document Management
A feature that allows users to upload, store, and share documents related to the project, including
specifications, drawings, and other important files.
*** Design Tools
A feature that includes design tools such as 3D modeling software, CAD, and other tools to help
users create and visualize their projects.
*** Workflow Automation
A feature that automates repetitive tasks and workflows, reducing errors and streamlining the
project process.

Buildonomy would automate various workflows such as approval workflows, notification workflows, and
other project workflows. This would help streamline the project management process and make it more
efficient.
*** Budgeting and Cost Management
A feature that allows users to manage project budgets, track expenses, and generate reports to help
with cost management.
*** Quality Control
A feature that includes tools to ensure project quality, such as quality assurance checks and
testing.
*** Analytics and Reporting
A feature that provides users with real-time analytics and reporting to help them track progress,
identify areas for improvement, and make data-driven decisions.

Analytics such as resource utilization, cost breakdowns, and efficiency metrics will help users
understand how their project is doing and if they need to make any adjustments.
*** Integration
A feature that enables users to integrate with other software applications, such as project
management tools or accounting software.
*** Mobile Access
A feature that allows users to access the software application from their mobile devices, enabling
them to work on the go and stay connected to their projects at all times.
*** Visual Rendering
Buildonomy would also allow users to view 3D models of their projects to see how they will look when
complete. This would help in the design process and make it easier to visualize the final product.
**** 3D Models
**** Product History and Family (changes and branches)
**** Schedule and Gantt Views
**** Time-series aggregator views
**** State-machine/Procedure Workflow graphs
**** Bill of Materials Graphs
* DONE Astrolab

** Account Set up
:PROPERTIES:
:EFFORT:   2:00
:END:
** Meeting 2023-05-31
:PROPERTIES:
:EFFORT:   1:00
:END:

** Reading RFP and generating questions/risks
:LOGBOOK:
CLOCK: [2023-06-13 Tue 15:35]--[2023-06-13 Tue 16:05] =>  0:30
CLOCK: [2023-06-13 Tue 14:19]--[2023-06-13 Tue 14:37] =>  0:18
CLOCK: [2023-06-13 Tue 13:30]--[2023-06-13 Tue 13:37] =>  0:07
CLOCK: [2023-06-13 Tue 13:16]--[2023-06-13 Tue 13:16] =>  0:00
CLOCK: [2023-06-02 Fri 13:46]--[2023-06-02 Fri 14:30] =>  0:44
:END:

** Reading DRD and generating Questions/Risks
:LOGBOOK:
CLOCK: [2023-06-09 Fri 13:35]--[2023-06-09 Fri 14:30] =>  0:55
CLOCK: [2023-06-09 Fri 11:25]--[2023-06-09 Fri 12:08] =>  0:43
CLOCK: [2023-06-09 Fri 10:28]--[2023-06-09 Fri 11:04] =>  0:36
CLOCK: [2023-06-09 Fri 09:39]--[2023-06-09 Fri 09:47] =>  0:08
CLOCK: [2023-06-05 Mon 13:40]--[2023-06-05 Mon 15:18] =>  1:38
:END:
- Reviewed LTV confluence pages

** Risk tag up
:LOGBOOK:
CLOCK: [2023-06-12 Mon 14:11]--[2023-06-12 Mon 14:53] =>  0:42
CLOCK: [2023-06-02 Fri 15:00]--[2023-06-02 Fri 16:10] =>  1:10
:END:

** Jesse Tag Up
:LOGBOOK:
CLOCK: [2023-06-05 Mon 12:17]--[2023-06-05 Mon 12:34] =>  0:17
:END:

- Zero code for LTV, Mission One. Intend to write starting after proposal is submitted and there's
  an SDP in place.
- SDP will be based on Odyssey's COTS+ version
- Venturi vs Astrolab: Venturi group is a conglomerate under one guy in Monaco. Astrolab is under
  this umbrella, only investor so far is this founder.
- subcontracting to other groups in the conglomerate for battery packs and tires
- Odyssey are full partners in the LTV proposal
- LTV proposal is primed by Astrolab, with Axiom and Odyssey as partners
- 'frenimies' with spacex, astrolab took some current employees
** Denise Tag Up
:LOGBOOK:
CLOCK: [2023-06-13 Tue 15:11]--[2023-06-13 Tue 15:34] =>  0:23
CLOCK: [2023-06-09 Fri 14:30]--[2023-06-09 Fri 15:13] =>  0:43
:END:

She's out until 6/7

I requested Denise's input on what I should work on. We'll talk again on Monday

Assuming responsibility for drafting TA.4

** Look for leverage points on control of NASA review subcontractors - June
:LOGBOOK:
CLOCK: [2023-06-28 Wed 15:32]--[2023-06-28 Wed 16:05] =>  0:33
CLOCK: [2023-06-13 Tue 12:29]--[2023-06-13 Tue 13:16] =>  0:47
:END:
** Look for leverage points on control of NASA review subcontractors - July
:LOGBOOK:
CLOCK: [2023-07-10 Mon 13:00]--[2023-07-10 Mon 16:49] =>  3:49
CLOCK: [2023-07-07 Fri 11:30]--[2023-07-07 Fri 15:42] =>  4:12
CLOCK: [2023-07-07 Fri 08:32]--[2023-07-07 Fri 10:20] =>  1:48
CLOCK: [2023-07-04 Tue 13:04]--[2023-07-04 Tue 13:38] =>  0:34
CLOCK: [2023-07-03 Mon 15:41]--[2023-07-03 Mon 16:44] =>  1:03
:END:
Talk to Julie Jiru to coordinate if there's a leverage point to gain insight and access to NASA
subcontract language for subcontractors who are responsible for insight and review activities.

Propsed we need a feedback mechanism such that:

- each rid has a notional cost to the submitter
- the goal is for the cost to be worth the reward
- can gamify this by having each rid have a submittal cost and the response provides a value

The problem is particularly bad for subcontractors, who are much more likely to act as
"disinterested observer" because of their disconnect with the actual program's objectives.

Introduce "RID Codes" That Astrolab assigns for each received RID. We have workflows for each
type. Program management has metrics associated with that assignment that flags working groups that
are breaking down.

There's a relationship between RIDs and Insight working group agenda's and NASA accountability. We
need to get this firm.

Currently Astrolab is responsible for each Insight Working Group Agenda.

out of each meeting
- attendance
- Astrolab's perceived value assessment, NASA's perceived value assessment

Each working group needs a:
- List of core members and their roles from NASA and Astrolab

----



Notes on Working Group Accountability process

Per working group we request that Astrolab and NASA independently track the following:

- The roles and names of their core team members
- Per a) DRD, b) Milestone Data Delivery, and c) Working Group Meeting

- Overall time spent and number of team members participating (preparing/reviewing)

- Per RID levied on the above: Program value categories (proposed categories are below)

----

# Proposal: A Feedback and Accountability Process for Certification Working Groups

Certification is an inherently adversarial process. Product owners endeavor to design and construct
a system capable of surpassing product success criteria whereas V&V criteria owners ensure the
intention of such criteria are satisfactorily met. Although this relationship is adversarial,
product owners and criteria owners are still partners; they simply approach the relationship between
product and evaluation criteria from different perspectives. Participation is aligned when both
partners are united by the overarching goal of ensuring program and operational success.

A well-run certification program is a positive sum proposition. The conflict between criteria and
product improves both the product, the criteria, and program itself. Nevertheless, the structure of
the certification process introduces opportunity for misalignment between the incentives of product,
criteria and program itself. As mission managers are the most likely parties to be aligned mission
success --- they are after all accountable for managing the program in order to achieve its
operational objectives --- they are least likely to experience misalignment between their role and
their personal incentives. As such, misalignment within the certification process can be adequately
controlled through the active participation of program management in assessing the performance
of each certification team. This in itself presents considerable difficulty as the reason to have
separate teams in the first place is due to the inherent complexity and domain expertise necessary
to evaluate the subsystems of any complex aerospace program. Therefore, mission management must
principally operate against aggregate and standardized information in order to assess whether more
direct intervention is necessary to resolve performance issues within a certification team.

To address the issue of certification misalignment, Astrolab proposes incorporation of the following
process for collecting and assessing metrics on the performance of all NASA-Astrolab certification
partnerships. This process is designed to fit easily into existing program workflows and helps to
ensure that certification responsible owners (product, certification criteria, as well as mission
management) stay accountable to the goals and constraints of the overarching Lunar Vehicle
Program. The proposal is as follows:

## Collection of Standardized Performance Metrics:

This proposal revolves around collecting and assessing metrics on the perceived value and effort
expended by product and criteria owners while performing their responsibilities with one another. By
aggregating metrics in a standard manner across each data product required for certification
purposes, the performance of each insight and certification working group team can be fairly
assessed and structural or personnel issues quickly brought to light in a fair and
non-discriminatory manner. Astrlab proposes that criteria and product teams each independently
annotate each certification collaboration item they bear responsibility for with the following information:

1. The value the item represents to the program. Proposed value ratings of:

  * -3: Subtracts significant value from the program
  * -2: Subtracts value from the program
  * -1: Subtracts insignificant value from the program
  *  0: Neither adds nor subtracts value away from the program
  * +1: Adds insignificant value to the program
  * +2: Adds value away to the program
  * +3: Adds significant value to the program

2. The number of hours the team spent in aggregate authoring, reviewing, revising, and/or responding
   to the item

We define certification collaboration items to encompass the following data products:

- DRD Deliverable
- Milestone Data Deliverable
- RID
- Working Group Agenda Item

In addition 
For each working group, the member's name, contact information, and responsibilities are
available. For each working group meeting, attendance is recorded.

Assessment of Performance


Perverse Incentives
- Regulatory Capture
- Intransigence
- Misalignment between product/criteria and Mission Success

Insufficient Expertise

Initiating Corrective Action due to Inadequate Performance

Arguments and Counterarguments:

Argument: Self-reported metrics, collected through surveys and the like, present an intrinsic
problem of data quality and consistency. Such metrics must be freely given in order to be of
sufficient quality to use, and most givers of such metrics have no personal incentive to offer them,
as their value is all captured in their aggregation and not the individual records.

Counterargument: In the proposal we can divide the personnel into three competing teams, each of
which is incentivized to provide accurate information in order to make their job easier. For
example, if criteria owners are given inadequate product data for their evaluation purposes, it will
take them longer to assess and the data sources they are provided with represent only marginal value
for their programmatic role. By accurately recording the effort the criteria team puts into review,
endemic issues with the pedagogical value of the underlying data source are exposed separately from
the day-to-day responsibility of identifying material issues (RIDS) in the performance of the
product for acheiving programmatic success. By expressing the value and effort the team perceives
for each deliverable, when inevetable conflicts between their adversarial partners arise, such as
when mission managers think the process is taking too long, or when product owners can't understand
why their results are not quickly accepted forthright, this assessment data protects the team by
adding quantitative rigor to their responsibilities in a way that can be fairly assessed in
comparison to the effort and value perceived by their counterparts.

** TA.2 Certification draft - July
:LOGBOOK:
CLOCK: [2023-07-07 Fri 07:42]--[2023-07-07 Fri 08:30] =>  0:48
:END:
** TA.2 Certification draft - June
:LOGBOOK:
CLOCK: [2023-06-30 Fri 08:11]--[2023-06-30 Fri 12:28] =>  4:17
CLOCK: [2023-06-29 Thu 14:54]--[2023-06-29 Thu 16:02] =>  1:08
CLOCK: [2023-06-29 Thu 12:55]--[2023-06-29 Thu 13:01] =>  0:06
CLOCK: [2023-06-28 Wed 11:38]--[2023-06-28 Wed 11:45] =>  0:07
CLOCK: [2023-06-28 Wed 10:17]--[2023-06-28 Wed 11:38] =>  1:21
CLOCK: [2023-06-28 Wed 07:56]--[2023-06-28 Wed 09:34] =>  1:38
CLOCK: [2023-06-27 Tue 14:30]--[2023-06-27 Tue 16:14] =>  1:44
CLOCK: [2023-06-27 Tue 11:24]--[2023-06-27 Tue 12:44] =>  1:20
CLOCK: [2023-06-15 Thu 13:12]--[2023-06-15 Thu 16:10] =>  2:58
CLOCK: [2023-06-12 Mon 14:53]--[2023-06-12 Mon 16:08] =>  1:15
CLOCK: [2023-06-12 Mon 13:47]--[2023-06-12 Mon 14:10] =>  0:23
CLOCK: [2023-06-09 Fri 15:30]--[2023-06-09 Fri 15:56] =>  0:26
CLOCK: [2023-06-09 Fri 07:41]--[2023-06-09 Fri 09:32] =>  1:51
CLOCK: [2023-06-09 Fri 05:52]--[2023-06-09 Fri 06:13] =>  0:21
CLOCK: [2023-06-09 Fri 05:37]--[2023-06-09 Fri 05:45] =>  0:08
CLOCK: [2023-06-08 Thu 15:20]--[2023-06-08 Thu 16:00] =>  0:40
:END:
Drafted text, need review and a bunch of diagrams. Likely a lot of this content belongs somewhere
else.

Make high level cert state machine diagram, and anatomy of a certification gate

review certification and milestones for consistency

Fixed up Lordina's rendering of the Anatomy of a Certification Gate Diagram

** TA.4 Review and Editing - June
:LOGBOOK:
CLOCK: [2023-06-29 Thu 13:07]--[2023-06-29 Thu 14:54] =>  1:47
CLOCK: [2023-06-14 Wed 13:41]--[2023-06-14 Wed 15:46] =>  2:05
CLOCK: [2023-06-14 Wed 11:46]--[2023-06-14 Wed 12:31] =>  0:45
CLOCK: [2023-06-14 Wed 10:00]--[2023-06-14 Wed 10:46] =>  0:46
CLOCK: [2023-06-14 Wed 08:14]--[2023-06-14 Wed 08:40] =>  0:26
CLOCK: [2023-06-14 Wed 07:26]--[2023-06-14 Wed 07:43] =>  0:17
CLOCK: [2023-06-14 Wed 05:59]--[2023-06-14 Wed 06:15] =>  0:16
:END:

Integration with milestones and (re)certificataion

Helping Bala with rationale behind standards adoption

** MA.2 Review and Editing - June
:LOGBOOK:
CLOCK: [2023-06-26 Mon 13:28]--[2023-06-26 Mon 15:04] =>  1:36
:END:
** Insight Task Basis of Estimate (BOE) Review - June
:LOGBOOK:
CLOCK: [2023-06-26 Mon 15:07]--[2023-06-26 Mon 15:51] =>  0:44
:END:

Ensure all insight related work is mapped to SMA BOE or Insight BOE and ensure the work is not
double-booked.

* Home
** TODO 2023 Budget Estimate
** DONE 529 Accounts for the Kids
** TODO vanguard.com/robo-advisor
** DONE Den Doors
** DONE Raised Beds
** DONE [#A] April Planting
** DONE Get Potted Trees outside
** Fall Planting
DEADLINE: <2023-07-01 Sat>
** DONE floor shoe trim
** TODO Patio
** DONE Check on crawlspace related to furnace exhaust pipe leak
** TODO Den Ceiling
** TODO Paint touchups throughout house
* DTW Chapter
** TODO Finish Committee Letter Draft
** TODO Contact A2/Detroit YIMBY for their recommended state legislation reforms
** TODO Create List of organizations we would like to get to sign the committee letter
** TODO [#A] Publish Newsletter
DEADLINE: <2023-04-23 Sun +1m>
** TODO Monthly Meeting
DEADLINE: <2023-05-08 Mon +1m>
** TODO Send Meeting Reminder
DEADLINE: <2023-05-07 Sun +1m>
** TODO Organize letter transmittal event
** TODO Schedule Monthly Markus Tagup
DEADLINE: <2023-04-28 Fri>
** DONE [#A] Get DTW Logo finished
